# For more information, see the Configuration Guide:
# https://www.librechat.ai/docs/configuration/librechat_yaml

# Configuration version (required)
version: 1.2.1

# Cache settings: Set to true to enable caching
cache: true

#interface:
#  modelSelect: true
#
# this breaks grouping by provider ..
#modelSpecs:
#  prioritize: true
#  addedEndpoints:
#    - openAI
#    - anthropic
#    - custom
#  list:
#   - name: gpt-4.1
#     label: "GPT-4.1"
#     iconURL: openAI
#     preset:
#       endpoint: "OpenAI"
#       model: "openai/gpt-4.1"
#       modelLabel: "GPT-4.1"
#   - name: gpt-4.1-mini
#     label: "GPT-4.1-mini"
#     iconURL: openAI
#     preset:
#       endpoint: "OpenAI"
#       model: "openai/gpt-4.1-mini"
#       modelLabel: "GPT-4.1-mini"
#   - name: gpt-4.1-nano
#     label: "GPT-4.1-nano"
#     iconURL: openAI
#     preset:
#       endpoint: "OpenAI"
#       model: "openai/gpt-4.1-nano"
#       modelLabel: "GPT-4.1-nano"
#   - name: o4-mini
#     label: "o4-mini"
#     iconURL: openAI
#     preset:
#       endpoint: "OpenAI"
#       model: "openai/o4-mini"
#       modelLabel: "o4-mini"
#   - name: o3-mini
#     label: "o3-mini"
#     iconURL: openAI
#     preset:
#       endpoint: "OpenAI"
#       model: "openai/o3-mini"
#       modelLabel: "o3-mini"
#   - name: o3
#     label: "o3"
#     iconURL: openAI
#     preset:
#       endpoint: "OpenAI"
#       model: "openai/o3"
#       modelLabel: "o3"
#   - name: o1-mini
#     label: "o1-mini"
#     iconURL: openAI
#     preset:
#       endpoint: "OpenAI"
#       model: "openai/o1-mini"
#       modelLabel: "o1-mini"
#   - name: gpt-4o-mini
#     label: "gpt-4o-mini"
#     iconURL: openAI
#     preset:
#       endpoint: "OpenAI"
#       model: "openai/gpt-4o-mini"
#       modelLabel: "GPT-4o-mini"
#   - name: gpt-4o
#     label: "gpt-4o"
#     iconURL: openAI
#     preset:
#       endpoint: "OpenAI"
#       model: "openai/gpt-4o"
#       modelLabel: "GPT-4o"
#   - name: gpt-4-turbo
#     label: "gpt-4-turbo"
#     iconURL: openAI
#     preset:
#       endpoint: "OpenAI"
#       model: "openai/gpt-4-turbo"
#       modelLabel: "GPT-4-turbo"
#   - name: gpt-3.5-turbo
#     label: "gpt-3.5-turbo"
#     iconURL: openAI
#     preset:
#       endpoint: "OpenAI"
#       model: "openai/gpt-3.5-turbo"
#       modelLabel: "GPT-3.5-turbo"
#   - name: gpt-4
#     label: "gpt-4"
#     iconURL: openAI
#     preset:
#       endpoint: "OpenAI"
#       model: "openai/gpt-4"
#       modelLabel: "GPT-4"
#
#   - name: "claude-opus-4"
#     label: "claude-opus-4"
#     iconURL: anthropic
#     preset:
#       endpoint: "anthropic"
#       model: "claude-opus-4-20250514"
#       modelLabel: "Claude Opus 4"
#
# File strategy s3/firebase
# fileStrategy: "s3"

endpoints:
  custom:
## moved to litellm
#    # Mistral AI Example
#    - name: 'Mistral' # Unique name for the endpoint
#      # For `apiKey` and `baseURL`, you can use environment variables that you define.
#      # recommended environment variables:
#      apiKey: '${MISTRAL_API_KEY}'
#      baseURL: 'https://api.mistral.ai/v1'
#
#      # Models configuration
#      models:
#        # List of default models to use. At least one value is required.
#        default: ['mistral-tiny', 'mistral-small', 'mistral-medium']
#        # Fetch option: Set to true to fetch models from API.
#        fetch: true # Defaults to false.
#
#      # Optional configurations
#
#      # Title Conversation setting
#      titleConvo: true # Set to true to enable title conversation
#
#      # Title Method: Choose between "completion" or "functions".
#      # titleMethod: "completion"  # Defaults to "completion" if omitted.
#
#      # Title Model: Specify the model to use for titles.
#      titleModel: 'mistral-tiny' # Defaults to "gpt-3.5-turbo" if omitted.
#
#      # Summarize setting: Set to true to enable summarization.
#      # summarize: false
#
#      # Summary Model: Specify the model to use if summarization is enabled.
#      # summaryModel: "mistral-tiny"  # Defaults to "gpt-3.5-turbo" if omitted.
#
#      # Force Prompt setting: If true, sends a `prompt` parameter instead of `messages`.
#      # forcePrompt: false
#
#      # The label displayed for the AI model in messages.
#      modelDisplayLabel: 'Mistral' # Default is "AI" when not set.
#
#      # Add additional parameters to the request. Default params will be overwritten.
#      # addParams:
#      # safe_prompt: true # This field is specific to Mistral AI: https://docs.mistral.ai/api/
#
#      # Drop Default params parameters from the request. See default params in guide linked below.
#      # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:
#      dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']
    - name: "OpenAI"
      iconURL: openAI
      baseURL: "http://litellm:8000/v1"
      apiKey: "passbolt://0dc3646b-9766-49c5-9ea0-a9eee2cfe9b80dc3646b-9766-49c5-9ea0-a9eee2cfe9b8/custom_fields/LITELLM_MASTER_KEY"
      models:
        default:
         - openai/gpt-4.1
         - openai/gpt-4.1-mini
         - openai/gpt-4.1-nano
         - openai/o4-mini
         - openai/o3-mini
         - openai/o3
         - openai/o1-mini
         - openai/gpt-4o-mini
         - openai/gpt-4o
         - openai/gpt-4-turbo
         - openai/gpt-3.5-turbo
         - openai/gpt-4
         # TURBO-16
         - openai/gpt-5
         - openai/gpt-5-nano
         - openai/gpt-5-mini
         - openai/gpt-5-pro
        fetch: false
      dropParams: ["user"] # user: DTM-4592

    - name: "Anthropic"
      iconURL: anthropic
      baseURL: "http://litellm:8000/anthropic/v1"
      apiKey: "passbolt://0dc3646b-9766-49c5-9ea0-a9eee2cfe9b80dc3646b-9766-49c5-9ea0-a9eee2cfe9b8/custom_fields/LITELLM_MASTER_KEY"
      models:
        default:
         - claude-opus-4-20250514
         - claude-sonnet-4-20250514
         - claude-3-7-sonnet-20250219
         - claude-3-5-sonnet-20240620
         - claude-3-haiku-20240307
         - claude-3-opus-20240229
         - claude-3-5-sonnet-20240620
         - claude-3-sonnet-20240229
         - claude-2.1
         - claude-2
         - claude-instant-1.2
         - claude-instant-1
        fetch: false
      dropParams:
        - stop
        - user
        - frequency_penalty
        - presence_penalty


    - name: "Mistral"
      iconURL: /assets/mistral.png
      baseURL: "http://litellm:8000/v1"
      apiKey: "passbolt://0dc3646b-9766-49c5-9ea0-a9eee2cfe9b80dc3646b-9766-49c5-9ea0-a9eee2cfe9b8/custom_fields/LITELLM_MASTER_KEY"
      models:
        default:
         - mistral/magistral-medium-latest
         - mistral/magistral-small-latest
         - mistral/mistral-medium-latest
         - mistral/mistral-large-latest
         - mistral/pixtral-large-latest
         - mistral/mistral-moderation-latest
         - mistral/ministral-3b-latest
         - mistral/ministral-8b-latest
         - mistral/open-mistral-nemo
         - mistral/mistral-small-latest
         - mistral/devstral-small-latest
         - mistral/devstral-medium-latest
         - mistral/mistral-saba-latest
         - mistral/codestral-latest
         - mistral/mistral-ocr-latest
         - mistral/voxtral-small-latest
         - mistral/voxtral-mini-latest
        fetch: false
      dropParams: ["user"] # user: DTM-4592

    - name: "Gemini"
      iconURL: google
      baseURL: "http://litellm:8000/v1"
      apiKey: "passbolt://0dc3646b-9766-49c5-9ea0-a9eee2cfe9b80dc3646b-9766-49c5-9ea0-a9eee2cfe9b8/custom_fields/LITELLM_MASTER_KEY"
      models:
        default:
         - gemini/gemini-2.5-pro
         - gemini/gemini-2.5-flash
         - gemini/gemini-2.5-flash-lite
         - gemini/gemini-2.0-flash
         - gemini/gemini-2.0-flash-lite
# imagegeneration did not work in testing
#         - gemini/imagen-4.0-generate-preview-06-06
#         - gemini/imagen-4.0-ultra-generate-preview-06-06
#         - gemini/imagen-3.0-generate-002
#         - gemini/veo-3.0-generate-preview
#         - gemini/veo-2.0-generate-001
# live models failed in testing
#         - gemini/gemini-live-2.5-flash-preview
#         - gemini/gemini-2.0-flash-live-001
        fetch: false
      dropParams: ["user"] # user: DTM-4592

webSearch:
  # Search Provider Configuration
  serperApiKey: "${SERPER_API_KEY}"
  #searxngInstanceUrl: "${SEARXNG_INSTANCE_URL}"
  #searxngApiKey: "${SEARXNG_API_KEY}"
  searchProvider: "serper" # Options: "serper", "searxng"

  # Scraper Configuration
  firecrawlApiKey: "${FIRECRAWL_API_KEY}"
  firecrawlApiUrl: "${FIRECRAWL_API_URL}"
  scraperType: "firecrawl" # Options: "firecrawl", "serper"

  # Reranker Configuration
  jinaApiKey: "${JINA_API_KEY}"
  #cohereApiKey: "${COHERE_API_KEY}"
  rerankerType: "jina" # Options: "jina", "cohere"

  # General Settings
  scraperTimeout: 60000 # Timeout in milliseconds for scraper requests (default: 7500)
  safeSearch: 1 # Options: 0 (OFF), 1 (MODERATE - default), 2 (STRICT)

# TURBO-20 // Codex suggestest not documented in git ...
ocr:
  strategy: mistral_ocr
  apiKey: "${MISTRAL_API_KEY}"
  baseURL: "https://api.mistral.ai/v1"
